{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10282831,"sourceType":"datasetVersion","datasetId":6363319},{"sourceId":10284654,"sourceType":"datasetVersion","datasetId":6364390}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install underthesea mlflow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:39:27.972305Z","iopub.execute_input":"2024-12-25T08:39:27.972583Z","iopub.status.idle":"2024-12-25T08:39:39.951640Z","shell.execute_reply.started":"2024-12-25T08:39:27.972560Z","shell.execute_reply":"2024-12-25T08:39:39.950774Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m629.7/629.7 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:49:01.859178Z","iopub.execute_input":"2024-12-25T08:49:01.859453Z","iopub.status.idle":"2024-12-25T08:49:01.863496Z","shell.execute_reply.started":"2024-12-25T08:49:01.859422Z","shell.execute_reply":"2024-12-25T08:49:01.862557Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"!pip install pyvi\n!pip install tqdm\n!pip install keras\n!pip install -q datasets\n!pip -q install underthesea mlflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:39:52.965992Z","iopub.execute_input":"2024-12-25T08:39:52.966507Z","iopub.status.idle":"2024-12-25T08:40:10.002302Z","shell.execute_reply.started":"2024-12-25T08:39:52.966483Z","shell.execute_reply":"2024-12-25T08:40:10.001326Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\nCollecting sklearn-crfsuite (from pyvi)\n  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.5.0)\nRequirement already satisfied: python-crfsuite>=0.9.7 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.11)\nRequirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.5)\nDownloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\nInstalling collected packages: sklearn-crfsuite, pyvi\nSuccessfully installed pyvi-0.1.1 sklearn-crfsuite-0.5.0\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\nRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\nRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input\nfrom keras.layers import Dense, Dropout, Concatenate\nfrom keras.layers import LSTM, Embedding, Bidirectional, GRU\nfrom keras.layers import SpatialDropout1D, Conv1D, GlobalAveragePooling1D, GlobalMaxPooling1D\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom keras.initializers import Constant\nfrom keras.preprocessing.sequence import pad_sequences\n#from keras.preprocessing.text import Tokenizer\nfrom keras.losses import BinaryCrossentropy, CategoricalCrossentropy\nimport pickle\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import classification_report\nimport collections\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom gensim import models\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\nfrom pyvi.ViTokenizer import tokenize\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport numpy as np\nfrom pyarrow.lib import _Weakrefable\nimport pyarrow\n# from datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:40:10.003533Z","iopub.execute_input":"2024-12-25T08:40:10.003852Z","iopub.status.idle":"2024-12-25T08:40:25.671969Z","shell.execute_reply.started":"2024-12-25T08:40:10.003824Z","shell.execute_reply":"2024-12-25T08:40:25.671109Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def replace_values(value):\n    if value == 0:\n        return np.nan  # Thay 0 thành null (NaN)\n    elif value == 1:\n        return 0\n    elif value == 2:\n        return 1\n    elif value == 3:\n        return 2\n    return value\n\n\ndata_train = pd.read_csv('/kaggle/input/sentimentabsa/data_train.csv')\ndata_val = pd.read_csv('/kaggle/input/sentimentabsa/data_val.csv')\ndata_test = pd.read_csv('/kaggle/input/sentimentabsa/data_test.csv')\n\n# Áp dụng hàm thay thế cho các cột A, B, C, D\ncolumns_to_replace = ['Quality', 'Smell', 'Shipping', 'Packing', 'Price', 'Other', 'General']\ndata_train[columns_to_replace] = data_train[columns_to_replace].applymap(replace_values)\ndata_test[columns_to_replace] = data_test[columns_to_replace].applymap(replace_values)\ndata_val[columns_to_replace] = data_val[columns_to_replace].applymap(replace_values)\n\n\ndata_train.drop('Unnamed: 0', axis = 1, inplace = True)\ndata_val.drop('Unnamed: 0', axis = 1, inplace = True)\ndata_test.drop('Unnamed: 0', axis = 1, inplace = True)\ndata_test.rename(columns={'Tokenized': 'processed_content'}, inplace=True)\ndata_train.rename(columns={'Tokenized': 'processed_content'}, inplace=True)\ndata_val.rename(columns={'Tokenized': 'processed_content'}, inplace=True)\ndata_test.rename(columns={'Quality': 'quality'}, inplace=True)\ndata_train.rename(columns={'Quality': 'quality'}, inplace=True)\ndata_val.rename(columns={'Quality': 'quality'}, inplace=True)\ndata_train.rename(columns={'Smell': 'smell'}, inplace=True)\ndata_test.rename(columns={'Smell': 'smell'}, inplace=True)\ndata_val.rename(columns={'Smell': 'smell'}, inplace=True)\ndata_val.rename(columns={'Shipping': 'shipping'}, inplace=True)\ndata_train.rename(columns={'Shipping': 'shipping'}, inplace=True)\ndata_test.rename(columns={'Shipping': 'shipping'}, inplace=True)\ndata_test.rename(columns={'Packing': 'packing'}, inplace=True)\ndata_train.rename(columns={'Packing': 'packing'}, inplace=True)\ndata_val.rename(columns={'Packing': 'packing'}, inplace=True)\ndata_train.rename(columns={'Price': 'price'}, inplace=True)\ndata_val.rename(columns={'Price': 'price'}, inplace=True)\ndata_test.rename(columns={'Price': 'price'}, inplace=True)\ndata_val.rename(columns={'Other': 'others'}, inplace=True)\ndata_test.rename(columns={'Other': 'others'}, inplace=True)\ndata_train.rename(columns={'Other': 'others'}, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:40:49.253020Z","iopub.execute_input":"2024-12-25T08:40:49.253338Z","iopub.status.idle":"2024-12-25T08:40:49.443804Z","shell.execute_reply.started":"2024-12-25T08:40:49.253305Z","shell.execute_reply":"2024-12-25T08:40:49.442959Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-6-1b4dc075d9a1>:19: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  data_train[columns_to_replace] = data_train[columns_to_replace].applymap(replace_values)\n<ipython-input-6-1b4dc075d9a1>:20: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  data_test[columns_to_replace] = data_test[columns_to_replace].applymap(replace_values)\n<ipython-input-6-1b4dc075d9a1>:21: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  data_val[columns_to_replace] = data_val[columns_to_replace].applymap(replace_values)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def make_outputs(df):\n    outputs = []\n    max_columns = len(df.columns) - 2  # Fixed number of columns\n    for row in range(len(df)):\n        row_one_hot = []\n        for col in range(1, min(max_columns + 1, len(df.columns)-1)):\n            sentiment = df.iloc[row, col]\n            if pd.isna(sentiment):\n                one_hot = [0, 0, 0, 0]  # Default for NaN\n            elif sentiment == 0: one_hot = [1, 0, 0, 0]\n            elif sentiment == 1: one_hot = [0, 1, 0, 0]\n            elif sentiment == 2: one_hot = [0, 0, 1, 0]\n            elif sentiment == 3: one_hot = [0, 0, 0, 1]\n            else:\n                raise ValueError(f\"Unexpected sentiment value {sentiment} at row {row}, column {col}\")\n            row_one_hot.append(one_hot)\n        outputs.append(row_one_hot)\n    return np.array(outputs, dtype='uint8')\n\n# Example usage\nlabel_train = make_outputs(data_train)\nlabel_val = make_outputs(data_val)\nlabel_test = make_outputs(data_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:47:24.016910Z","iopub.execute_input":"2024-12-25T08:47:24.017196Z","iopub.status.idle":"2024-12-25T08:47:26.355748Z","shell.execute_reply.started":"2024-12-25T08:47:24.017175Z","shell.execute_reply":"2024-12-25T08:47:26.355065Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"label_train = make_outputs(data_train)\nlabel_val = make_outputs(data_val)\nlabel_test = make_outputs(data_test)\n\nprint('Train outputs:', label_train.shape)\nprint('Validate outputs:', label_val.shape)\nprint('Test outputs:', label_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:47:50.312604Z","iopub.execute_input":"2024-12-25T08:47:50.313051Z","iopub.status.idle":"2024-12-25T08:47:52.350142Z","shell.execute_reply.started":"2024-12-25T08:47:50.313012Z","shell.execute_reply":"2024-12-25T08:47:52.349312Z"}},"outputs":[{"name":"stdout","text":"Train outputs: (10198, 7, 4)\nValidate outputs: (2186, 7, 4)\nTest outputs: (2185, 7, 4)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from underthesea import word_tokenize\nperiod_strip = re.compile(r'(?!<=\\d)(\\.)(?!\\d)')\ncomma_strip = re.compile(r'(\\d)(,)(\\d)')\npunctuation_chars = re.escape(r';/[]\"{}()=+\\_-><@`,?!.')\npunctuation = re.compile(r'([{}])'.format(re.escape(punctuation_chars)))\npunctuation_with_a_space = re.compile(r'(?<= )([{0}])|([{0}])(?= )'.format(punctuation_chars))\n\ndef process_punctuation(s):\n    if punctuation.search(s) is None:\n        return s\n    s = punctuation_with_a_space.sub('', s)\n    if re.search(comma_strip, s) is not None:\n        s = s.replace(',', '')\n    s = punctuation.sub(' ', s)\n    s = period_strip.sub('', s)\n    return s.strip()\n\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n\ndef encode_data(df):\n    return tokenizer(data_train['processed_content'].apply(lambda x: word_tokenize(process_punctuation(x.lower()), format=\"text\")).tolist(), padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"tf\")\n\ntrain_encodings = encode_data(data_train)\nval_encodings = encode_data(data_val)\ntest_encodings = encode_data(data_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:49:09.895573Z","iopub.execute_input":"2024-12-25T08:49:09.895900Z","iopub.status.idle":"2024-12-25T08:49:28.872746Z","shell.execute_reply.started":"2024-12-25T08:49:09.895873Z","shell.execute_reply":"2024-12-25T08:49:28.872057Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:49:48.089322Z","iopub.execute_input":"2024-12-25T08:49:48.089634Z","iopub.status.idle":"2024-12-25T08:49:48.093450Z","shell.execute_reply.started":"2024-12-25T08:49:48.089610Z","shell.execute_reply":"2024-12-25T08:49:48.092521Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from transformers import RobertaForSequenceClassification, RobertaTokenizer, TrainingArguments, Trainer\nimport torch\nfrom torch.nn import BCEWithLogitsLoss\nfrom torch.utils.data import Dataset, DataLoader\n\n# Tải mô hình và tokenizer\nmodel_name = \"vinai/phobert-base-v2\"\nnum_labels = 7\n\nfrom transformers import RobertaForSequenceClassification, RobertaConfig, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n\ntexts_train = data_train['processed_content'].apply(lambda x: word_tokenize(process_punctuation(x.lower()), format=\"text\")).values\nlabels_train = label_train\n\ntexts_val = data_val['processed_content'].apply(lambda x: word_tokenize(process_punctuation(x.lower()), format=\"text\")).values\nlabels_val = label_val\nfrom transformers import TrainerCallback\n\nclass EarlyStoppingCallback(TrainerCallback):\n    def __init__(self, early_stopping_patience=3):\n        self.early_stopping_patience = early_stopping_patience\n        self.early_stopping_counter = 0\n        self.best_loss = float('inf')\n\n    def on_evaluate(self, args, state, control, **kwargs):\n        eval_loss = kwargs.get(\"metrics\", {}).get(\"eval_loss\", None)\n        if eval_loss is not None:\n            if eval_loss < self.best_loss:\n                self.best_loss = eval_loss\n                self.early_stopping_counter = 0\n            else:\n                self.early_stopping_counter += 1\n            if self.early_stopping_counter >= self.early_stopping_patience:\n                control.should_training_stop = True\n                print(f\"Early stopping triggered: No improvement in the last {self.early_stopping_patience} evaluations.\")\n\nclass MultiLabelDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=256):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, item):\n        text = self.texts[item]\n        labels = self.labels[item]\n        label_tensor = torch.tensor(labels, dtype=torch.float32).view(-1)\n        encoding = self.tokenizer(\n            text,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': label_tensor\n        }\n\ndataset_train = MultiLabelDataset(texts_train, labels_train, tokenizer)\ndataset_val = MultiLabelDataset(texts_val, labels_val, tokenizer)\nmodel = RobertaForSequenceClassification.from_pretrained(\"vinai/phobert-base-v2\", num_labels=28)\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=10,\n    per_device_train_batch_size=20,\n    per_device_eval_batch_size=20,\n    warmup_steps=500,\n    weight_decay=0.01,\n    learning_rate=1e-5,\n    logging_dir='./logs',\n    logging_steps=10,\n    eval_strategy=\"epoch\",  # evaluation_strategy\n    report_to=\"none\"        # W&B\n)\n\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        loss_fct = BCEWithLogitsLoss()\n        loss = loss_fct(logits, labels)\n        return (loss, outputs) if return_outputs else loss\n\n    def predict(self, test_dataset):\n        predictions, label_ids, metrics = super().predict(test_dataset)\n        probs = torch.sigmoid(torch.tensor(predictions))\n        preds = (probs).int()\n        return preds, label_ids, metrics\n\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset_train,\n    eval_dataset=dataset_val,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\ntrainer.train()\ntrainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:50:25.409238Z","iopub.execute_input":"2024-12-25T08:50:25.409559Z","iopub.status.idle":"2024-12-25T09:37:29.604148Z","shell.execute_reply.started":"2024-12-25T08:50:25.409536Z","shell.execute_reply":"2024-12-25T09:37:29.603355Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e7be105b1f44a5ead443a57d886216d"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2550' max='2550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2550/2550 46:31, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.441400</td>\n      <td>0.415058</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.180000</td>\n      <td>0.170201</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.125400</td>\n      <td>0.120896</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.111200</td>\n      <td>0.107615</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.104700</td>\n      <td>0.099845</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.095800</td>\n      <td>0.093339</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.092800</td>\n      <td>0.088773</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.084200</td>\n      <td>0.083714</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.086000</td>\n      <td>0.081069</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.080600</td>\n      <td>0.080229</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='108' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [55/55 00:39]\n    </div>\n    "},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.08022899925708771,\n 'eval_runtime': 18.7105,\n 'eval_samples_per_second': 116.833,\n 'eval_steps_per_second': 2.94,\n 'epoch': 10.0}"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"model_path = '/kaggle/working/'\nmodel.save_pretrained(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T09:37:29.605162Z","iopub.execute_input":"2024-12-25T09:37:29.605382Z","iopub.status.idle":"2024-12-25T09:37:30.928561Z","shell.execute_reply.started":"2024-12-25T09:37:29.605364Z","shell.execute_reply":"2024-12-25T09:37:30.927899Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"texts_test = data_test['processed_content'].apply(lambda x: word_tokenize(process_punctuation(x.lower()), format=\"text\")).values\nlabels_test = label_test\ndataset_test = MultiLabelDataset(texts_test, labels_test, tokenizer)\nprediction = trainer.predict(dataset_test)\nprediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T09:38:27.659490Z","iopub.execute_input":"2024-12-25T09:38:27.659951Z","iopub.status.idle":"2024-12-25T09:38:46.481652Z","shell.execute_reply.started":"2024-12-25T09:38:27.659911Z","shell.execute_reply":"2024-12-25T09:38:46.480565Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(tensor([[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32),\n array([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 1., 0.],\n        [0., 0., 1., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n {'test_loss': 0.08034634590148926,\n  'test_runtime': 17.5883,\n  'test_samples_per_second': 124.23,\n  'test_steps_per_second': 3.127})"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"pred = prediction\nlabels = pred[1].reshape(len( pred[1]), 7, 4)\npreds = pred[0].reshape(len( pred[1]), 7, 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T09:38:53.708172Z","iopub.execute_input":"2024-12-25T09:38:53.708534Z","iopub.status.idle":"2024-12-25T09:38:53.712872Z","shell.execute_reply.started":"2024-12-25T09:38:53.708495Z","shell.execute_reply":"2024-12-25T09:38:53.711901Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"aspect_labels = 1 - labels[:, :, 0]\naspect_preds = 1 - preds[:, :, 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T09:38:57.264056Z","iopub.execute_input":"2024-12-25T09:38:57.264350Z","iopub.status.idle":"2024-12-25T09:38:57.268942Z","shell.execute_reply.started":"2024-12-25T09:38:57.264327Z","shell.execute_reply":"2024-12-25T09:38:57.267926Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# aspect detection\nfrom sklearn.metrics import f1_score\naspect_f1 = f1_score(aspect_labels.flatten(), aspect_preds.flatten())\naspect_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T09:38:58.402991Z","iopub.execute_input":"2024-12-25T09:38:58.403286Z","iopub.status.idle":"2024-12-25T09:38:58.413749Z","shell.execute_reply.started":"2024-12-25T09:38:58.403264Z","shell.execute_reply":"2024-12-25T09:38:58.412686Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"0.9951052856345061"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# Sentiment\nsentiment_labels = np.argmax(labels[:, : , 1:], axis = -1)\nsentiment_preds = np.argmax(preds[: , : , 1:], axis = -1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T09:39:00.761947Z","iopub.execute_input":"2024-12-25T09:39:00.762256Z","iopub.status.idle":"2024-12-25T09:39:00.767229Z","shell.execute_reply.started":"2024-12-25T09:39:00.762221Z","shell.execute_reply":"2024-12-25T09:39:00.766293Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"sentiment_labels = np.argmax(labels[:, : , 1:], axis = -1)\nsentiment_preds = np.argmax(preds[: , : , 1:], axis = -1)\nsentiment_f1 = f1_score(sentiment_labels.flatten(), sentiment_preds.flatten(), average = 'weighted')\nsentiment_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T09:39:01.291434Z","iopub.execute_input":"2024-12-25T09:39:01.291741Z","iopub.status.idle":"2024-12-25T09:39:01.303459Z","shell.execute_reply.started":"2024-12-25T09:39:01.291717Z","shell.execute_reply":"2024-12-25T09:39:01.302705Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"0.8182459831480563"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\n# Đảm bảo chuyển tensor về CPU và numpy array nếu cần\nnegative_preds = preds[:, :, 1].cpu().numpy().flatten() if torch.is_tensor(preds) else preds[:, :, 1].flatten()\nnegative_labels = labels[:, :, 1].cpu().numpy().flatten() if torch.is_tensor(labels) else labels[:, :, 1].flatten()\n\nneutral_preds = preds[:, :, 2].cpu().numpy().flatten() if torch.is_tensor(preds) else preds[:, :, 2].flatten()\nneutral_labels = labels[:, :, 2].cpu().numpy().flatten() if torch.is_tensor(labels) else labels[:, :, 2].flatten()\n\npositive_preds = preds[:, :, 3].cpu().numpy().flatten() if torch.is_tensor(preds) else preds[:, :, 3].flatten()\npositive_labels = labels[:, :, 3].cpu().numpy().flatten() if torch.is_tensor(labels) else labels[:, :, 3].flatten()\n\n# Tính F1-score\nf1_negative = f1_score(negative_labels, negative_preds)\nf1_neutral = f1_score(neutral_labels, neutral_preds)\nf1_positive = f1_score(positive_labels, positive_preds)\n\nprint(\"F1 Score - Negative:\", f1_negative)\nprint(\"F1 Score - Neutral:\", f1_neutral)\nprint(\"F1 Score - Positive:\", f1_positive)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T09:39:02.073200Z","iopub.execute_input":"2024-12-25T09:39:02.073505Z","iopub.status.idle":"2024-12-25T09:39:02.096896Z","shell.execute_reply.started":"2024-12-25T09:39:02.073480Z","shell.execute_reply":"2024-12-25T09:39:02.096004Z"}},"outputs":[{"name":"stdout","text":"F1 Score - Negative: 0.0\nF1 Score - Neutral: 0.0\nF1 Score - Positive: 0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"y_pred = preds\n\ny_true = labels\n\n# Xử lý và chuyển đổi sang nhãn tương ứng\nsentiment_labels = np.argmax(y_true[:, :, 1:], axis=1)\nsentiment_preds = np.argmax(y_pred[:,:, 1:], axis=1)\n\n# Cách 1: Tính F1 score với average='macro'\nf1_macro = f1_score(sentiment_labels.flatten(), sentiment_preds.flatten(), average='macro')\n\n# Cách 2: Tính F1 cho từng sentiment riêng lẻ\nnegative_preds = y_pred[:,:, 1]\nnegative_labels = y_true[:,:, 1]\nneutral_preds = y_pred[:, :,2]\nneutral_labels = y_true[:, :,2]\npositive_preds = y_pred[:, :,3]\npositive_labels = y_true[:, :,3]\n\nf1_negative = f1_score(negative_labels.flatten(), negative_preds.flatten())\nf1_neutral = f1_score(neutral_labels.flatten(), neutral_preds.flatten())\nf1_positive = f1_score(positive_labels.flatten(), positive_preds.flatten())\n\n# Lấy trung bình của các F1 scores\nf1_average = np.mean([f1_negative, f1_neutral, f1_positive])\n\n# In kết quả\nprint(\"F1 Score (Macro Average):\", f1_macro)\nprint(\"F1 Scores Individually: Negative = {}, Neutral = {}, Positive = {}\".format(f1_negative, f1_neutral, f1_positive))\nprint(\"F1 Score (Average of Individual Scores):\", f1_average)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T09:39:05.464517Z","iopub.execute_input":"2024-12-25T09:39:05.464831Z","iopub.status.idle":"2024-12-25T09:39:05.491498Z","shell.execute_reply.started":"2024-12-25T09:39:05.464807Z","shell.execute_reply":"2024-12-25T09:39:05.490518Z"}},"outputs":[{"name":"stdout","text":"F1 Score (Macro Average): 0.12745358410391366\nF1 Scores Individually: Negative = 0.0, Neutral = 0.0, Positive = 0.0\nF1 Score (Average of Individual Scores): 0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport numpy as np\n\nfor aspect_index in range(5):\n    print(f\"Aspect {aspect_index + 1}\")\n    aspect_true = np.argmax(labels[:, aspect_index, :], axis=1)\n    aspect_pred = np.argmax(preds[:, aspect_index, :], axis=1)\n    \n    # Get the unique classes in aspect_true and aspect_pred\n    unique_classes = np.unique(np.concatenate((aspect_true, aspect_pred)))\n    \n    # Map unique_classes to the corresponding target_names\n    all_target_names = [\"None\", \"Negative\", \"Neutral\", \"Positive\"]\n    target_names = [all_target_names[i] for i in unique_classes]\n    \n    print(classification_report(aspect_true, aspect_pred, target_names=target_names, zero_division=0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T09:39:53.698233Z","iopub.execute_input":"2024-12-25T09:39:53.698528Z","iopub.status.idle":"2024-12-25T09:39:53.742421Z","shell.execute_reply.started":"2024-12-25T09:39:53.698507Z","shell.execute_reply":"2024-12-25T09:39:53.741600Z"}},"outputs":[{"name":"stdout","text":"Aspect 1\n              precision    recall  f1-score   support\n\n        None       0.67      1.00      0.81      1472\n    Negative       0.00      0.00      0.00        62\n     Neutral       0.00      0.00      0.00       651\n\n    accuracy                           0.67      2185\n   macro avg       0.22      0.33      0.27      2185\nweighted avg       0.45      0.67      0.54      2185\n\nAspect 2\n              precision    recall  f1-score   support\n\n        None       0.98      1.00      0.99      2151\n    Negative       0.00      0.00      0.00        21\n     Neutral       0.00      0.00      0.00        13\n\n    accuracy                           0.98      2185\n   macro avg       0.33      0.33      0.33      2185\nweighted avg       0.97      0.98      0.98      2185\n\nAspect 3\n              precision    recall  f1-score   support\n\n        None       0.91      1.00      0.95      1994\n    Negative       0.00      0.00      0.00         3\n     Neutral       0.00      0.00      0.00       188\n\n    accuracy                           0.91      2185\n   macro avg       0.30      0.33      0.32      2185\nweighted avg       0.83      0.91      0.87      2185\n\nAspect 4\n              precision    recall  f1-score   support\n\n        None       0.91      1.00      0.95      1990\n    Negative       0.00      0.00      0.00         2\n     Neutral       0.00      0.00      0.00       193\n\n    accuracy                           0.91      2185\n   macro avg       0.30      0.33      0.32      2185\nweighted avg       0.83      0.91      0.87      2185\n\nAspect 5\n              precision    recall  f1-score   support\n\n        None       0.74      1.00      0.85      1608\n    Negative       0.00      0.00      0.00        20\n     Neutral       0.00      0.00      0.00       557\n\n    accuracy                           0.74      2185\n   macro avg       0.25      0.33      0.28      2185\nweighted avg       0.54      0.74      0.62      2185\n\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}